{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the DistilBERT Sentiment Analysis Model\n",
    "\n",
    "This notebook allows you to explore the trained DistilBERT model, load it from a configuration file, and test it with your own text input using an interactive widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from src.data import YelpDataProcessor\n",
    "from src.models import DistilBERTSentimentModel\n",
    "import logging\n",
    "\n",
    "# Configure logging to be less verbose in the notebook\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Models\n",
    "\n",
    "First, let's load the model configuration and trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4c087d5ae34aef9af93788a689c9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Config:', index=1, options=(('Default DistilBERT Config', 'model_configs/distilbert_defaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select which configuration to use\n",
    "config_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Default DistilBERT Config', 'model_configs/distilbert_default.yaml'),\n",
    "        ('Tuned DistilBERT Config', 'model_configs/distilbert_tuning_v1.yaml')\n",
    "    ],\n",
    "    value='model_configs/distilbert_tuning_v1.yaml',\n",
    "    description='Config:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(config_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)    \n",
    "    return config\n",
    "\n",
    "def load_model_and_processor(config_path):\n",
    "    \"\"\"Load model and data processor based on config\"\"\"\n",
    "    # Load configuration\n",
    "    print(f\"Loading configuration from {config_path}\")\n",
    "    config = load_config(config_path)\n",
    "    \n",
    "    # Extract configuration values\n",
    "    data_config = config.get('data', {})\n",
    "    model_config = config.get('model', {})\n",
    "    hp_tuning_config = config.get('hyperparameter_tuning', {})\n",
    "    best_params = hp_tuning_config.get('best_params', None)\n",
    "    \n",
    "    # Apply best parameters if they exist, otherwise use defaults\n",
    "    effective_model_config = model_config.copy()\n",
    "    if best_params is not None:\n",
    "        if 'dropout' in best_params:\n",
    "            effective_model_config['dropout'] = best_params['dropout']\n",
    "                \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize data processor with DistilBERT tokenizer\n",
    "    pretrained_model = effective_model_config.get('pretrained_model', 'distilbert-base-cased')\n",
    "    data_processor = YelpDataProcessor(\n",
    "        data_path=data_config.get('path'),\n",
    "        max_length=data_config.get('max_length', 128),\n",
    "        batch_size=data_config.get('batch_size', 32),\n",
    "        tokenizer_name=pretrained_model\n",
    "    )\n",
    "    \n",
    "    # Load label encoder\n",
    "    label_encoder_path = 'models/label_encoder.pkl'\n",
    "    if os.path.exists(label_encoder_path):\n",
    "        with open(label_encoder_path, 'rb') as f:\n",
    "            data_processor.label_encoder = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Label encoder not found. Loading sample data to create one.\")\n",
    "        df = data_processor.load_data()\n",
    "        data_processor.prepare_data_bert(df)\n",
    "    \n",
    "    # Determine model name/directory\n",
    "    model_name = config.get('name', 'distilbert_sentiment_model')\n",
    "    model_dir = f\"models/{model_name}\"\n",
    "    \n",
    "    # Build model with configuration\n",
    "    model = DistilBERTSentimentModel(\n",
    "        num_classes=len(data_processor.label_encoder.classes_),\n",
    "        dropout=effective_model_config.get('dropout', 0.1),\n",
    "        pretrained_model=pretrained_model\n",
    "    )\n",
    "    \n",
    "    # Load model weights if available\n",
    "    best_model_path = os.path.join(model_dir, 'model_best_f1.pt')\n",
    "    if os.path.exists(best_model_path):\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device, weights_only=True))\n",
    "        print(f\"Loaded trained model from {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"Trained model not found at {best_model_path}. Using untrained model.\")\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    return model, data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from model_configs/distilbert_tuning_v1.yaml\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model from models/distilbert_sentiment_model/model_best_f1.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the model and processor based on selected config\n",
    "model, data_processor = load_model_and_processor(config_selector.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architecture and Configuration\n",
    "\n",
    "Let's examine our model architecture and the configuration that was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Sentiment Analysis Model Architecture:\n",
      "DistilBERTSentimentModel(\n",
      "  (bert): DistilBertForSequenceClassification(\n",
      "    (distilbert): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x TransformerBlock(\n",
      "            (attention): DistilBertSdpaAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Configuration:\n",
      "\n",
      "DATA:\n",
      "  batch_size: 64\n",
      "  max_length: 128\n",
      "  path: data/yelp_reviews.json\n",
      "\n",
      "HYPERPARAMETER_TUNING:\n",
      "  best_params: {'batch_size': 16, 'dropout': 0.19825184780826133, 'learning_rate': 0.004734664034654023, 'optimizer': 'rmsprop', 'weight_decay': 2.538226449992215e-05}\n",
      "  cv_folds: 3\n",
      "  enabled: True\n",
      "  n_epochs: 1\n",
      "  n_trials: 5\n",
      "\n",
      "MODEL:\n",
      "  dropout: 0.1\n",
      "  pretrained_model: distilbert-base-cased\n",
      "\n",
      "TRAINING:\n",
      "  epochs: 10\n",
      "  learning_rate: 1e-3\n",
      "  optimizer: adamw\n",
      "  scheduler: onecycle\n",
      "  seed: 42\n",
      "  weight_decay: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture\n",
    "print(\"DistilBERT Sentiment Analysis Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Display configuration details\n",
    "config = load_config(config_selector.value)\n",
    "print(\"\\nConfiguration:\")\n",
    "for section, params in config.items():\n",
    "    print(f\"\\n{section.upper()}:\")\n",
    "    if isinstance(params, dict):\n",
    "        for param, value in params.items():\n",
    "            print(f\"  {param}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Text Classification\n",
    "\n",
    "Now let's create a widget to input your own text and see the sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, data_processor, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Process text and make a prediction using DistilBERT\"\"\"\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the text (keep case for DistilBERT)\n",
    "    processed_text = data_processor.preprocess_text(text, lower=False)\n",
    "    \n",
    "    # Tokenize using DistilBERT tokenizer\n",
    "    encoding = data_processor.bert_tokenizer(\n",
    "        processed_text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=data_processor.max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move tensors to the right device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    # Get class name and probabilities\n",
    "    predicted_label = data_processor.label_encoder.classes_[predicted_class]\n",
    "    probs_dict = {data_processor.label_encoder.classes_[i]: prob.item() for i, prob in enumerate(probabilities)}\n",
    "    \n",
    "    return predicted_label, probs_dict, processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9f03e5f1014694944b8a90369f27aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='This restaurant was amazing! The food was delicious and the service was excellent.', descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda689e25c3e46a4837cf1cb76d2c00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Analyze Sentiment', style=ButtonStyle(), tooltip='Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eea239930f14936997c9443b207785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create UI elements\n",
    "text_input = widgets.Textarea(\n",
    "    value='This restaurant was amazing! The food was delicious and the service was excellent.',\n",
    "    placeholder='Enter your text here...',\n",
    "    description='Review:',\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='Analyze Sentiment',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to analyze the sentiment of the text'\n",
    ")\n",
    "\n",
    "config_change_button = widgets.Button(\n",
    "    description='Change Config',\n",
    "    button_style='info',\n",
    "    tooltip='Click to load model from the selected config'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Text styling for output\n",
    "def style_prediction(label, probabilities):\n",
    "    \"\"\"Style the prediction output with colors and bars\"\"\"\n",
    "    colors = {\n",
    "        'positive': 'green',\n",
    "        'neutral': 'orange',\n",
    "        'negative': 'red'\n",
    "    }\n",
    "    \n",
    "    result = f\"<h3>Prediction: <span style='color:{colors.get(label, 'blue')}'>{label.upper()}</span></h3>\"\n",
    "    result += \"<h4>Confidence Scores:</h4>\"\n",
    "    \n",
    "    for label, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = prob * 100\n",
    "        color = colors.get(label, 'blue')\n",
    "        result += f\"<div style='margin-bottom:5px;'>\"\n",
    "        result += f\"<span style='display:inline-block; width:100px;'>{label}:</span>\"\n",
    "        result += f\"<div style='display:inline-block; width:{percentage}%; background-color:{color}; height:20px;'></div>\"\n",
    "        result += f\"<span style='margin-left:10px;'>{percentage:.2f}%</span>\"\n",
    "        result += \"</div>\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define button click handlers\n",
    "def on_run_button_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        if model is None or data_processor is None:\n",
    "            print(\"Error: Model or data processor not loaded properly.\")\n",
    "            return\n",
    "        \n",
    "        text = text_input.value\n",
    "        if not text.strip():\n",
    "            print(\"Please enter some text to analyze.\")\n",
    "            return\n",
    "        \n",
    "        predicted_label, probabilities, processed_text = predict_sentiment(\n",
    "            text, model, data_processor\n",
    "        )\n",
    "        \n",
    "        print(f\"Original text: {text}\")\n",
    "        print(f\"Processed text: {processed_text}\")\n",
    "        display(HTML(style_prediction(predicted_label, probabilities)))\n",
    "\n",
    "def on_config_change_clicked(b):\n",
    "    global model, data_processor\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        try:\n",
    "            model, data_processor = load_model_and_processor(config_selector.value)\n",
    "            print(\"Model and data processor loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Attach click handlers\n",
    "run_button.on_click(on_run_button_clicked)\n",
    "config_change_button.on_click(on_config_change_clicked)\n",
    "\n",
    "# Display UI\n",
    "display(text_input)\n",
    "display(widgets.HBox([run_button, config_change_button]))\n",
    "display(output_area)\n",
    "\n",
    "# Initialize prediction\n",
    "on_run_button_clicked(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring Model Predictions on Sample Reviews\n",
    "\n",
    "Let's look at some sample reviews and how the model predicts them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1: The food was absolutely terrible. I'll never come back to this restaurant again.\n",
      "Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Sample 2: The service was okay, but the food was mediocre. Not worth the price.\n",
      "Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Sample 3: It was an average experience. Nothing special but not bad either.\n",
      "Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Sample 4: The staff was friendly and the atmosphere was nice, but the food was just decent.\n",
      "Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Sample 5: Amazing experience! The chef prepared the best meal I've had in years.\n",
      "Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "sample_reviews = [\n",
    "    \"The food was absolutely terrible. I'll never come back to this restaurant again.\",\n",
    "    \"The service was okay, but the food was mediocre. Not worth the price.\",\n",
    "    \"It was an average experience. Nothing special but not bad either.\",\n",
    "    \"The staff was friendly and the atmosphere was nice, but the food was just decent.\",\n",
    "    \"Amazing experience! The chef prepared the best meal I've had in years.\"\n",
    "]\n",
    "\n",
    "for i, review in enumerate(sample_reviews):\n",
    "    print(f\"\\nSample {i+1}: {review}\")\n",
    "    predicted_label, probabilities, processed_text = predict_sentiment(\n",
    "        review, model, data_processor\n",
    "    )\n",
    "    print(f\"Prediction: {predicted_label}\")\n",
    "    print(\"Probabilities:\")\n",
    "    for label, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {label}: {prob:.4f} ({prob*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploring Token Importance\n",
    "\n",
    "For DistilBERT, we can use Integrated Gradients to visualize token importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_attributions(text, model, data_processor, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Get token attributions using a simple gradient-based approach\"\"\"\n",
    "    model.train()  # Need gradients\n",
    "    \n",
    "    # Preprocess text\n",
    "    processed_text = data_processor.preprocess_text(text, lower=False)\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = data_processor.bert_tokenizer(\n",
    "        processed_text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=data_processor.max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Get tokens for display\n",
    "    tokens = data_processor.bert_tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Create embeddings tensor that requires grad\n",
    "    model.bert.distilbert.embeddings.word_embeddings.weight.requires_grad = True\n",
    "    \n",
    "    # Forward pass with gradients\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    predicted_label = data_processor.label_encoder.classes_[predicted_class]\n",
    "    \n",
    "    # Compute gradients with respect to predicted class\n",
    "    model.zero_grad()\n",
    "    output[0, predicted_class].backward()\n",
    "    \n",
    "    # Get embeddings gradient\n",
    "    token_embeddings = model.bert.distilbert.embeddings.word_embeddings(input_ids)\n",
    "    if hasattr(token_embeddings, 'grad') and token_embeddings.grad is not None:\n",
    "        # Compute L2 norm of gradients as token importance\n",
    "        token_importance = torch.norm(token_embeddings.grad, dim=2)[0].detach().cpu().numpy()\n",
    "    else:\n",
    "        print(\"Warning: Could not compute gradients for token importance\")\n",
    "        token_importance = np.ones(len(tokens))\n",
    "    \n",
    "    # Set model back to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Only include tokens with non-zero attention mask\n",
    "    mask = attention_mask[0].detach().cpu().numpy()\n",
    "    \n",
    "    # Filter special tokens and padding\n",
    "    special_tokens = ['[CLS]', '[SEP]', '[PAD]']\n",
    "    filtered_tokens = []\n",
    "    filtered_importance = []\n",
    "    \n",
    "    for i, (token, imp, m) in enumerate(zip(tokens, token_importance, mask)):\n",
    "        if m > 0 and token not in special_tokens:\n",
    "            filtered_tokens.append(token)\n",
    "            filtered_importance.append(imp)\n",
    "    \n",
    "    return filtered_tokens, filtered_importance, predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualize which tokens the model finds important:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786120d6aa734473899fbc7131b637de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='The food was delicious but the service was terrible.', description='Text:', layout=Layout(heigâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544c0a3f18684efcae34b998ce7ca96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Visualize Tokens', style=ButtonStyle(), tooltip='Click to visualizâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c114b666f14f2aa8f7c5350c582ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a function to visualize token importance\n",
    "def visualize_token_importance(text):\n",
    "    tokens, importance, predicted_label = get_token_attributions(text, model, data_processor)\n",
    "    \n",
    "    if tokens is None or importance is None:\n",
    "        print(\"Couldn't extract token importance.\")\n",
    "        return\n",
    "    \n",
    "    # Normalize importance for visualization\n",
    "    if len(importance) > 0:\n",
    "        max_importance = max(importance)\n",
    "        if max_importance > 0:\n",
    "            norm_importance = [imp / max_importance for imp in importance]\n",
    "        else:\n",
    "            norm_importance = [0.0] * len(importance)\n",
    "    else:\n",
    "        norm_importance = []\n",
    "    \n",
    "    # Create HTML visualization\n",
    "    html = f\"<h3>Token Importance for: <span style='color:blue'>{predicted_label.upper()}</span></h3>\"\n",
    "    html += \"<div style='line-height: 2.5; font-family: monospace; font-size: 16px;'>\"\n",
    "    \n",
    "    for token, weight in zip(tokens, norm_importance):\n",
    "        # Map weight to color intensity\n",
    "        color_intensity = int(255 * (1 - weight))\n",
    "        background_color = f\"rgb(255, {color_intensity}, {color_intensity})\"\n",
    "        \n",
    "        html += f\"<span style='background-color: {background_color}; padding: 3px; margin: 2px; border-radius: 3px;'>{token}</span>\"\n",
    "    \n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "# Create UI for token importance visualization\n",
    "importance_text = widgets.Textarea(\n",
    "    value='The food was delicious but the service was terrible.',\n",
    "    placeholder='Enter text to visualize token importance...',\n",
    "    description='Text:',\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "importance_button = widgets.Button(\n",
    "    description='Visualize Tokens',\n",
    "    button_style='success',\n",
    "    tooltip='Click to visualize token importance'\n",
    ")\n",
    "\n",
    "importance_output = widgets.Output()\n",
    "\n",
    "def on_importance_button_clicked(b):\n",
    "    with importance_output:\n",
    "        importance_output.clear_output()\n",
    "        visualize_token_importance(importance_text.value)\n",
    "\n",
    "importance_button.on_click(on_importance_button_clicked)\n",
    "\n",
    "# Display importance UI\n",
    "print(\"\\nVisualize which tokens the model finds important:\")\n",
    "display(importance_text)\n",
    "display(importance_button)\n",
    "display(importance_output)\n",
    "\n",
    "# Initialize visualization\n",
    "on_importance_button_clicked(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing DistilBERT with LSTM Results\n",
    "\n",
    "You can manually compare the predictions from the DistilBERT model with the LSTM model by running similar examples in both notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Challenging Example 1: The food wasn't bad, but I wouldn't say it was good either.\n",
      "DistilBERT Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Challenging Example 2: Great atmosphere, but terrible food and rude service.\n",
      "DistilBERT Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Challenging Example 3: Well, this was an interesting experience to say the least.\n",
      "DistilBERT Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Challenging Example 4: This restaurant is just as good as any other chain restaurant nearby.\n",
      "DistilBERT Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n",
      "\n",
      "Challenging Example 5: I've had better, but I've also had much worse.\n",
      "DistilBERT Prediction: positive\n",
      "Probabilities:\n",
      "  positive: 1.0000 (100.00%)\n",
      "  negative: 0.0000 (0.00%)\n",
      "  neutral: 0.0000 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Add some challenging reviews that may highlight differences between models\n",
    "challenging_reviews = [\n",
    "    \"The food wasn't bad, but I wouldn't say it was good either.\", # Ambiguous sentiment\n",
    "    \"Great atmosphere, but terrible food and rude service.\", # Mixed sentiment\n",
    "    \"Well, this was an interesting experience to say the least.\", # Subtle implied sentiment\n",
    "    \"This restaurant is just as good as any other chain restaurant nearby.\", # Comparative but neutral\n",
    "    \"I've had better, but I've also had much worse.\" # Balanced perspective\n",
    "]\n",
    "\n",
    "for i, review in enumerate(challenging_reviews):\n",
    "    print(f\"\\nChallenging Example {i+1}: {review}\")\n",
    "    predicted_label, probabilities, processed_text = predict_sentiment(\n",
    "        review, model, data_processor\n",
    "    )\n",
    "    print(f\"DistilBERT Prediction: {predicted_label}\")\n",
    "    print(\"Probabilities:\")\n",
    "    for label, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {label}: {prob:.4f} ({prob*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
